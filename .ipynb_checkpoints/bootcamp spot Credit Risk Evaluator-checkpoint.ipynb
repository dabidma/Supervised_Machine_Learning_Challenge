{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Risk Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the Data\n",
    "\n",
    "The data is located in the Challenge Files Folder:\n",
    "\n",
    "* `lending_data.csv`\n",
    "\n",
    "Import the data using Pandas. Display the resulting dataframe to confirm the import was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "lending_data_df = pd.read_csv('Resources/lending_data.csv')\n",
    "lending_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Model Performance\n",
    "\n",
    "You will be creating and comparing two models on this data: a Logistic Regression, and a Random Forests Classifier. Before you create, fit, and score the models, make a prediction as to which model you think will perform better. You do not need to be correct! \n",
    "\n",
    "Write down your prediction in the designated cells in your Jupyter Notebook, and provide justification for your educated guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I predict that the logistic regression will display a better model as not anyone will be given a loan and there's always a set range for how much a bank can loan. With this assumption, I doubt there will be any outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X_train, X_test, y_train, y_test\n",
    "y = lending_data_df[['loan_status']]\n",
    "X = lending_data_df[['loan_size', 'interest_rate', 'debt_to_income', 'num_of_accounts', 'derogatory_marks', 'total_debt']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, Fit and Compare Models\n",
    "\n",
    "Create a Logistic Regression model, fit it to the data, and print the model's score. Do the same for a Random Forest Classifier. You may choose any starting hyperparameters you like. \n",
    "\n",
    "Which model performed better? How does that compare to your prediction? Write down your results and thoughts in the designated markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a Logistic Regression model and print the model score\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: : 0.9920724996560737\n",
      "Test Score: : 0.9924680148576145\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression model score\n",
    "print(f\"Training Score: : {model.score(X_train, y_train)}\")\n",
    "print(f\"Test Score: : {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18653,    92],\n",
       "       [   54,   585]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a confusion matric\n",
    "y_true = y_test\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9924680148576145\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     18745\n",
      "           1       0.86      0.92      0.89       639\n",
      "\n",
      "    accuracy                           0.99     19384\n",
      "   macro avg       0.93      0.96      0.94     19384\n",
      "weighted avg       0.99      0.99      0.99     19384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classifcation report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9975409272252029\n",
      "Testing Score: 0.9917457697069748\n"
     ]
    }
   ],
   "source": [
    "print(f'Training Score: {rfc.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {rfc.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.68281143e-01 3.11504547e-01 1.88884656e-01 1.08351995e-01\n",
      " 1.11781830e-04 2.22865877e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create barchart to visualize\n",
    "import matplotlib.pyplot as plt\n",
    "features = rfc.feature_importances_\n",
    "print(features)\n",
    "plt.bar(x = range(len(features)), height=features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.07000000e+04, 7.67200000e+00, 4.31818182e-01, 2.28000000e+04],\n",
       "       [8.40000000e+03, 6.69200000e+00, 3.11926606e-01, 1.36000000e+04],\n",
       "       [9.00000000e+03, 6.96300000e+00, 3.49240781e-01, 1.61000000e+04],\n",
       "       ...,\n",
       "       [1.76000000e+04, 1.05950000e+01, 6.26400996e-01, 5.03000000e+04],\n",
       "       [1.63000000e+04, 1.00680000e+01, 6.01593625e-01, 4.53000000e+04],\n",
       "       [1.56000000e+04, 9.74200000e+00, 5.85062241e-01, 4.23000000e+04]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel = SelectFromModel(rfc)\n",
    "sel.fit(X_train_scaled, y_train.values.ravel())\n",
    "sel.get_support()\n",
    "sel.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:443: UserWarning: X has feature names, but SelectFromModel was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_selected_train, X_selected_test, y_train, y_test = train_test_split(sel.transform(X), y, random_state=1)\n",
    "scaler = StandardScaler().fit(X_selected_train)\n",
    "X_selected_train_scaled = scaler.transform(X_selected_train)\n",
    "X_selected_test_scaled = scaler.transform(X_selected_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9942908240473243\n",
      "Testing Score: 0.9936545604622369\n"
     ]
    }
   ],
   "source": [
    "rfc = LogisticRegression().fit(X_train_scaled, y_train.values.ravel())\n",
    "print(f'Training Score: {rfc.score(X_train_scaled, y_train.values.ravel())}')\n",
    "print(f'Testing Score: {rfc.score(X_test_scaled, y_test.values.ravel())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9942908240473243\n",
      "Testing Score: 0.9936545604622369\n"
     ]
    }
   ],
   "source": [
    "rfc = LogisticRegression()\n",
    "rfc.fit(X_selected_train_scaled, y_train.values.ravel())\n",
    "print(f'Training Score: {rfc.score(X_selected_train_scaled, y_train.values.ravel())}')\n",
    "print(f'Testing Score: {rfc.score(X_selected_test_scaled, y_test.values.ravel())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Which model performed better? How does that compare to your prediction? Replace the text in this markdown cell with your answers to these questions.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
